# -*- coding: utf-8 -*-
"""
Created on Thu Nov 23 10:52:38 2023

@author: bhanu's
"""

# import 
import pandas as pd
df = pd.read_excel("C:\\Users\\bhanu\\OneDrive\\Desktop\\data science assesments\\EastWestAirlines.xlsx",sheet_name='data')
df.head()
df.shape  
#-->(3999, 12)
df.info()
df.isnull().sum()

#EDA
#-->BOXPLOT 
import seaborn as sns
import matplotlib.pyplot as plt
data = df.iloc[:,0:12]
for column in data:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=df[column])
    plt.title(f" Horizontal Box Plot of {column}")
    plt.show()
# we can identify all the outliers at a time

#-->removing outliers
df1 = df.iloc[:,0:12]
from scipy import stats
# Define a threshold for Z-score (e.g., Z-score greater than 3 or less than -3 indicates an outlier)
z_threshold = 3
# Calculate the Z-scores for each column in the DataFrame
import numpy as np
z_scores = np.abs(stats.zscore(df1))

# Create a mask to identify rows with outliers
outlier_mask = (z_scores > z_threshold).any(axis=1)

# Remove rows with outliers from the DataFrame
df = df[~outlier_mask]
df.shape  
#-->(3630, 12)

#HISTOGRAM BUILDING, SKEWNESS AND KURTOSIS CALCULATION 
df.hist()
df.skew()
df.kurt()
df.describe()

# Create a pairplot for your DataFrame
import seaborn as sns
sns.pairplot(df)
plt.show()

# Generate a correlation matrix for our DataFrame
correlation_matrix = df.corr()

# Create a heatmap of the correlation matrix to gain insights
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 8))  
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()
"""
Values close to 1 indicate a strong positive correlation.
Values close to -1 indicate a strong negative correlation.
Values close to 0 indicate a weak or no correlation
"""

# Dendogram
import pandas as pd
import scipy.cluster.hierarchy as sch
import matplotlib.pyplot as plt
# Calculate the linkage matrix
linkage_matrix = sch.linkage(df, method='ward')
linkage_matrix
# Create a dendrogram
plt.figure(figsize=(12, 6))
dendrogram = sch.dendrogram(linkage_matrix)
plt.title('Dendrogram')
plt.xlabel('Data Points')
plt.ylabel('Euclidean Distances')
plt.show()

# defining x variables
X = df.iloc[:,0:13]
X
# AgglomerativeClustering
from sklearn.cluster import AgglomerativeClustering
cluster = AgglomerativeClustering(n_clusters = 5,affinity = 'euclidean',linkage = 'complete')
Y = cluster.fit_predict(X)
Y_new = pd.DataFrame(Y)
Y_new[0].value_counts()

# scatterplot
plt.figure(figsize=(10, 6))
plt.scatter(df.iloc[:, 0], df.iloc[:, 1], c=Y, cmap='viridis', marker='o', edgecolor='k')
plt.title('Agglomerative Clustering')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.show()

#K means clusterring (ellbow method)
from sklearn.cluster import KMeans
k = 3  # Adjust this value based on your requirements
# KMeans algorithm
kmeans = KMeans(n_clusters=k, random_state=0)
cluster_labels = kmeans.fit_predict(df)
cluster_centers = kmeans.cluster_centers_

# scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(df.iloc[:, 0], df.iloc[:, 1], c=cluster_labels, cmap='viridis', marker='o', edgecolor='k')
plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], s=200, c='red', label='Cluster Centers')
plt.title('K-Means Clustering')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()

#DBSCAN
from sklearn.cluster import DBSCAN
#DBSCAN algorithm
dbscan = DBSCAN(eps=0.5, min_samples=5)  
cluster_labels = dbscan.fit_predict(df)
#scatterplot 
plt.figure(figsize=(10, 6))
plt.scatter(df.iloc[:, 0], df.iloc[:, 1], c=cluster_labels, cmap='viridis', marker='o', edgecolor='k')
plt.title('DBSCAN Clustering')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.show()

# printing final data and also the noice data
db = DBSCAN(eps = 1.0,min_samples = 2)
X = pd.DataFrame(X)
db.fit(X)

Y = db.labels_
Y_new = pd.DataFrame(Y)
Y_new[0].value_counts()

df

df_new = pd.concat([df,Y_new],axis=1)

df_final = df_new[df_new[0] != -1]
df_final.shape


df_noise = df_new[df_new[0] == -1]
df_noise